{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# torch.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing\n",
    "\n",
    "Split data into train, validation and test:  \n",
    "80% train, 10% validation, 10% test:\n",
    "\n",
    "Years selected for test and validation (based of random number generation):\n",
    "Valid and test years pairs are selected within one year of seperation\n",
    "valid = 2022, 1999, 2008, 1990\n",
    "test = 2023,  1998, 2009, 1991\n",
    "\n",
    "Validation years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "datafolder = \"./data/\"\n",
    "merge_df = pd.DataFrame()\n",
    "for i, file in enumerate(os.listdir(datafolder)):\n",
    "    if i == 0:\n",
    "        merge_df = pd.read_csv(datafolder + file)\n",
    "    else:\n",
    "        df = pd.read_csv(datafolder + file)\n",
    "        merge_df = pd.merge(merge_df, df, on=\"month\")\n",
    "\n",
    "merge_df[\"month_num\"] = merge_df[\"month\"].apply(lambda x: int(x.split(\"-\")[1]))\n",
    "\n",
    "group_2 = ['2022', '1999', '2008', '1990']\n",
    "group_3 = ['2023', '2009', '1998', '1991']\n",
    "\n",
    "# Filter DataFrames by year\n",
    "valid_df = merge_df[merge_df['month'].str.split('-').str[0].isin(group_2)]\n",
    "test_df = merge_df[merge_df['month'].str.split('-').str[0].isin(group_3)]\n",
    "\n",
    "train_df = merge_df[~merge_df['month'].str.split('-').str[0].isin(group_2 + group_3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1982-01', '1982-02', '1982-03', '1982-04', '1982-05', '1982-06',\n",
       "       '1982-07', '1982-08', '1982-09', '1982-10', '1982-11', '1982-12',\n",
       "       '1983-01', '1983-02', '1983-03', '1983-04', '1983-05', '1983-06',\n",
       "       '1983-07', '1983-08', '1983-09', '1983-10', '1983-11', '1983-12',\n",
       "       '1984-01', '1984-02', '1984-03', '1984-04', '1984-05', '1984-06',\n",
       "       '1984-07', '1984-08', '1984-09', '1984-10', '1984-11', '1984-12',\n",
       "       '1985-01', '1985-02', '1985-03', '1985-04', '1985-05', '1985-06',\n",
       "       '1985-07', '1985-08', '1985-09', '1985-10', '1985-11', '1985-12',\n",
       "       '1986-01', '1986-02', '1986-03', '1986-04', '1986-05', '1986-06',\n",
       "       '1986-07', '1986-08', '1986-09', '1986-10', '1986-11', '1986-12',\n",
       "       '1987-01', '1987-02', '1987-03', '1987-04', '1987-05', '1987-06',\n",
       "       '1987-07', '1987-08', '1987-09', '1987-10', '1987-11', '1987-12',\n",
       "       '1988-01', '1988-02', '1988-03', '1988-04', '1988-05', '1988-06',\n",
       "       '1988-07', '1988-08', '1988-09', '1988-10', '1988-11', '1988-12',\n",
       "       '1989-01', '1989-02', '1989-03', '1989-04', '1989-05', '1989-06',\n",
       "       '1989-07', '1989-08', '1989-09', '1989-10', '1989-11', '1989-12',\n",
       "       '1992-01', '1992-02', '1992-03', '1992-04', '1992-05', '1992-06',\n",
       "       '1992-07', '1992-08', '1992-09', '1992-10', '1992-11', '1992-12',\n",
       "       '1993-01', '1993-02', '1993-03', '1993-04', '1993-05', '1993-06',\n",
       "       '1993-07', '1993-08', '1993-09', '1993-10', '1993-11', '1993-12',\n",
       "       '1994-01', '1994-02', '1994-03', '1994-04', '1994-05', '1994-06',\n",
       "       '1994-07', '1994-08', '1994-09', '1994-10', '1994-11', '1994-12',\n",
       "       '1995-01', '1995-02', '1995-03', '1995-04', '1995-05', '1995-06',\n",
       "       '1995-07', '1995-08', '1995-09', '1995-10', '1995-11', '1995-12',\n",
       "       '1996-01', '1996-02', '1996-03', '1996-04', '1996-05', '1996-06',\n",
       "       '1996-07', '1996-08', '1996-09', '1996-10', '1996-11', '1996-12',\n",
       "       '1997-01', '1997-02', '1997-03', '1997-04', '1997-05', '1997-06',\n",
       "       '1997-07', '1997-08', '1997-09', '1997-10', '1997-11', '1997-12',\n",
       "       '2000-01', '2000-02', '2000-03', '2000-04', '2000-05', '2000-06',\n",
       "       '2000-07', '2000-08', '2000-09', '2000-10', '2000-11', '2000-12',\n",
       "       '2001-01', '2001-02', '2001-03', '2001-04', '2001-05', '2001-06',\n",
       "       '2001-07', '2001-08', '2001-09', '2001-10', '2001-11', '2001-12',\n",
       "       '2002-01', '2002-02', '2002-03', '2002-04', '2002-05', '2002-06',\n",
       "       '2002-07', '2002-08', '2002-09', '2002-10', '2002-11', '2002-12',\n",
       "       '2003-01', '2003-02', '2003-03', '2003-04', '2003-05', '2003-06',\n",
       "       '2003-07', '2003-08', '2003-09', '2003-10', '2003-11', '2003-12',\n",
       "       '2004-01', '2004-02', '2004-03', '2004-04', '2004-05', '2004-06',\n",
       "       '2004-07', '2004-08', '2004-09', '2004-10', '2004-11', '2004-12',\n",
       "       '2005-01', '2005-02', '2005-03', '2005-04', '2005-05', '2005-06',\n",
       "       '2005-07', '2005-08', '2005-09', '2005-10', '2005-11', '2005-12',\n",
       "       '2006-01', '2006-02', '2006-03', '2006-04', '2006-05', '2006-06',\n",
       "       '2006-07', '2006-08', '2006-09', '2006-10', '2006-11', '2006-12',\n",
       "       '2007-01', '2007-02', '2007-03', '2007-04', '2007-05', '2007-06',\n",
       "       '2007-07', '2007-08', '2007-09', '2007-10', '2007-11', '2007-12',\n",
       "       '2010-01', '2010-02', '2010-03', '2010-04', '2010-05', '2010-06',\n",
       "       '2010-07', '2010-08', '2010-09', '2010-10', '2010-11', '2010-12',\n",
       "       '2011-01', '2011-02', '2011-03', '2011-04', '2011-05', '2011-06',\n",
       "       '2011-07', '2011-08', '2011-09', '2011-10', '2011-11', '2011-12',\n",
       "       '2012-01', '2012-02', '2012-03', '2012-04', '2012-05', '2012-06',\n",
       "       '2012-07', '2012-08', '2012-09', '2012-10', '2012-11', '2012-12',\n",
       "       '2013-01', '2013-02', '2013-03', '2013-04', '2013-05', '2013-06',\n",
       "       '2013-07', '2013-08', '2013-09', '2013-10', '2013-11', '2013-12',\n",
       "       '2014-01', '2014-02', '2014-03', '2014-04', '2014-05', '2014-06',\n",
       "       '2014-07', '2014-08', '2014-09', '2014-10', '2014-11', '2014-12',\n",
       "       '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06',\n",
       "       '2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12',\n",
       "       '2016-01', '2016-02', '2016-03', '2016-04', '2016-05', '2016-06',\n",
       "       '2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12',\n",
       "       '2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06',\n",
       "       '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12',\n",
       "       '2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06',\n",
       "       '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12',\n",
       "       '2019-01', '2019-02', '2019-03', '2019-04', '2019-05', '2019-06',\n",
       "       '2019-07', '2019-08', '2019-09', '2019-10', '2019-11', '2019-12',\n",
       "       '2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06',\n",
       "       '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12',\n",
       "       '2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06',\n",
       "       '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12',\n",
       "       '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06',\n",
       "       '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12',\n",
       "       '2025-01', '2025-02'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.month.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1990-01', '1990-02', '1990-03', '1990-04', '1990-05', '1990-06',\n",
       "       '1990-07', '1990-08', '1990-09', '1990-10', '1990-11', '1990-12',\n",
       "       '1999-01', '1999-02', '1999-03', '1999-04', '1999-05', '1999-06',\n",
       "       '1999-07', '1999-08', '1999-09', '1999-10', '1999-11', '1999-12',\n",
       "       '2008-01', '2008-02', '2008-03', '2008-04', '2008-05', '2008-06',\n",
       "       '2008-07', '2008-08', '2008-09', '2008-10', '2008-11', '2008-12',\n",
       "       '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06',\n",
       "       '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.month.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1991-01', '1991-02', '1991-03', '1991-04', '1991-05', '1991-06',\n",
       "       '1991-07', '1991-08', '1991-09', '1991-10', '1991-11', '1991-12',\n",
       "       '1998-01', '1998-02', '1998-03', '1998-04', '1998-05', '1998-06',\n",
       "       '1998-07', '1998-08', '1998-09', '1998-10', '1998-11', '1998-12',\n",
       "       '2009-01', '2009-02', '2009-03', '2009-04', '2009-05', '2009-06',\n",
       "       '2009-07', '2009-08', '2009-09', '2009-10', '2009-11', '2009-12',\n",
       "       '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06',\n",
       "       '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.month.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalised(df, predicting_column = \"total_rainfall\", min_max=True):\n",
    "    excluded_columns = [\"month\", predicting_column]\n",
    "\n",
    "    # Reorder the columns so that predicting value is at the end\n",
    "    cols = [col for col in df.columns if col not in excluded_columns]  # Get all columns except excluded ones\n",
    "    cols.append(predicting_column)  # Add \"total_rainfall\" at the end\n",
    "    df = df[cols]  # Reorder the DataFrame columns\n",
    "    # print(df)\n",
    "    merge_df_normalized_gaussian = df.copy()\n",
    "    merge_df_normalized_minmax = df.copy()\n",
    "\n",
    "    epsilon = 1e-10\n",
    "\n",
    "    for column in merge_df_normalized_gaussian.columns:\n",
    "        if column not in excluded_columns:\n",
    "            merge_df_normalized_gaussian[column] = (merge_df_normalized_gaussian[column] - merge_df_normalized_gaussian[column].mean()) / merge_df_normalized_gaussian[column].std()\n",
    "\n",
    "    for column in merge_df_normalized_minmax.columns:\n",
    "        if column not in excluded_columns:\n",
    "            merge_df_normalized_minmax[column] = (merge_df_normalized_minmax[column] - merge_df_normalized_minmax[column].min() + epsilon) / (merge_df_normalized_minmax[column].max() - merge_df_normalized_minmax[column].min() + epsilon)\n",
    "    return merge_df_normalized_minmax if min_max else merge_df_normalized_gaussian\n",
    "\n",
    "normalised_train_df = normalised(train_df)\n",
    "normalised_valid_df = normalised(valid_df)\n",
    "normalised_test_df = normalised(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "n_inputs = 48 # 48 months\n",
    "n_outputs = 6 # predicting 6 months ahead\n",
    "hidden_size = 32\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, n_input = 48, n_output = 6):\n",
    "        self.df = df\n",
    "        self.inputs = []\n",
    "        self.outputs = []\n",
    "\n",
    "        for i in range(n_input, len(df) - n_output):\n",
    "            self.inputs.append(df.iloc[i - n_input:i].values)\n",
    "            self.outputs.append(df.iloc[i:i + n_output][\"total_rainfall\"].values)        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index], self.outputs[index]\n",
    "    \n",
    "train = CustomDataset(normalised_train_df)\n",
    "valid = CustomDataset(normalised_valid_df)\n",
    "test = CustomDataset(normalised_test_df)\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=32, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, num_epochs, learning_rate):\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(inputs, model.initHidden())\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        if (epoch%25 == 0):\n",
    "            avg_loss = total_loss / len(dataloader)\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 3\n",
    "\n",
    "class RNN_model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN_model, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "    \n",
    "\n",
    "rnn_model = RNN_model(n_inputs, hidden_size, n_outputs, num_layers)\n",
    "rnn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "\n",
    "train(rnn_model, train_dataloader, num_epochs, learning_rate)\n",
    "\n",
    "torch.save(rnn_model.state_dict(), \"rnn_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
